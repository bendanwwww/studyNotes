mysql 基础结构
连接器 client与mysql的长链接建立&维护
缓存(key为sql value为结果 代价太大 基本废弃)
分析器(sql词法&语法分析)
优化器(生成sql执行计划 选择索引)
执行器(与存储引擎交互 执行sql)
存储引擎(innodb MyISAM memory)

write ahead log(日志先行)
db将数据写入磁盘时 现将其数据变化写入日志(innodb redo log / HDFS edit log) 然后异步写入磁盘
此操作可以减少大量io开销(日志顺序写 磁盘随机写) 同时当db崩溃时 可以通过日志恢复数据

mysql存储引擎(存储引擎对于表 而非整个数据库的全局设置)
mysql类似一个数据库平台 可以通过实现不同的存储引擎来成为不同类型的数据库(如 使用innodb作为事务型数据库 MyISAM作为非事务型数据库 memory作为内存型数据库 archive可以作为保存日志的数据库)
innodb 支持事务 支持crash-safe 对高并发读写做了极大的优化 是mysql当前版本的默认存储引擎
MyISAM 不支持事务 仅支持表级锁 支持全文索引 支持压缩表 最存储空间要求较小 且在某些场景下性能较高(没有innodb复杂的事务支持 且由于表占用空间较小 io开销小) 崩溃后恢复较为复杂且无法保证数据不丢失
memory 内存型引擎 数据不会落入磁盘 应用重启后数据丢失 使用hash作为存储数据结构 较高的读写效率
archive 不支持事务 仅支持select&inster操作 有较高的写效率 较合适作为日志存储使用
mysql在查询时产生的临时表 默认使用MyISAM存储引擎

mysql crash-safe保证与binlog/redo log 两阶段提交(2PC)
mysql innodb保证重启或崩溃时已提交的数据不会丢失
当数据写入时 首先写入redo log中 将redo log 此行状态置为prepare 当事务被提交时写入binlog 最后将事务中所有写入的redo log状态置为commit
redo log 存在于innodb中 binlog是mysql执行器自带的日志
redo log 用于crash时的数据恢复 binlog用于时间点的数据恢复以及主从同步
redo log 为环状数据结构 一个指针指向下次写入的地址 一个指针指向需要擦除的地址 若redo log写满 则会擦除最老的log
写日志时 先写入应用 cache 再写入os cache中 再刷入磁盘中 通过配置可在每次写入os cache时强制刷盘
每个redo log记录了一个LSN(log sequence number 日志序列号) 记录了当前重做日志的字节数 数据页中也记录了一个LSN 记录了当前已经刷入磁盘的重做日志字节数 当崩溃恢复时 可以根据两者的LSN差值 恢复丢失的数据

undo log(数据回滚日志 存在于undo segment 实现事务回滚或mvcc)
    包括insert undo log(插入语句的undo log 仅针对单个事务 当事务被提交后即可被删除)
        update undo log(更新/删除语句的undo log 由于mvcc的需要 当单个事务提交后不能立刻被删除 由定时purge操作 通过查询事务链表判断此事务释放被其他事务快照所引用 若未被引用则删除 同时删除索引上delete标识被该事务置为1的节点)

buffer pool
mysql通过buffer pool实现异步刷盘的策略 减少io的开销
mysql 允许存在多个buffer pool 来减少同一块内存区域频繁读写的压力 以及 扩容的便捷性(单纯增加一块buffer pool即可)
缓冲池中的缓存页包括 数据页 索引页 插入缓冲 锁信息 自适应哈希 数据字典信息
当页被访问时 先加载到buffer pool中 之后对此页的操作均在内存中进行 当页被置换或定时任务扫描命中时 再将页的修改刷入磁盘
buffer pool维护三个指向各个页的链表
free链表 在buffer pool所属的内存页中 哪些页是空闲的可以被写入数据
flush链表 内存页中哪些页被修改过 需要被刷入磁盘
LRU链表 内存页LRU置换算法维护的链表 由此实现LRU算法(最近最久未访问)置换页
buffer pool刷盘时机(check point)
当数据库关闭/重启时 主动将所有脏页刷入磁盘
使用定时任务每1s/10s主动将一部分脏页刷入磁盘
当buffer pool的空闲页小于一定数量时
当重做日志不可用时(重做日志最老的数据需要被覆盖) 将重做日志被清理的脏页刷入磁盘 保证数据库数据不丢失
当buffer pool脏页过多时

重做日志缓冲(redo log buffer)
为提高并发 redo log写入时也先写入缓存中 再异步刷入磁盘
有三个时机会将buffer中的数据刷入磁盘(os cache) 每隔1秒执行的定时任务 事务提交时 当buffer空闲空间小于50%时

额外内存池(innodb_additional_mem_pool)
用于存储缓冲控制对象信息(LRU 锁 等待) 当buffer pool较大时 此内存区域设置也要相应变大

innodb关键优化特性
change buffer 当对非主键索引页进行插入/修改&该索引不是唯一索引(插入 change buffer时不会检查索引页中的数据是否存在)&索引页不在buffer pool时 为减少io开销(对非聚簇索引页的写入是磁盘随机读写) 将此写入操作先放入 change buffer中 等待某个时机将对此索引页的全部修改操作同时刷入磁盘
    change buffer 分为insert buffer/delete buffer/purge buffer三种 对应对索引页的插入 逻辑删除 物理删除三种操作
    每一种change buffer 对应一个数据库全局的b+树 树的非叶子节点存放具体的表空间和数据页偏移量 叶子节点还存放了具体被修改的信息以及操作的时间顺序
    change buffer 刷入时机
        当索引页被写入buffer pool中时 将change buffer中的操作同时写入
        当非聚簇索引页空间小于一定值时(为保证写入change buffer的操作一定成功)
        定时任务刷入
两次写(double write) 防止当写入页时宕机导致的页文件损坏
    当buffer pool中的脏页需要刷盘时 先将脏页copy一份至double write buffer中 再将页刷盘至共享表空间 此时 磁盘中同一页同时存在两份(一份在共享表空间 一份在表的独立空间) 这样当刷入共享表空间或从共享表空间刷入表独立空间时发生宕机 都可保证至少有一页是完整的 恢复时可以根据完整的页和redo log 恢复数据
    os 部分类型的文件系统已经实现了部分写失效的防范机制 使用这些文件系统时可以不启用double write
自适应hash索引(adaptive hash index) 当某一个索引页访问非常频繁时(对顺序相同的字段查询超过100次或超过页记录数量的1/16) 则自动建立该索引页的hash表 提升查询效率
异步io 对于磁盘的读写使用AIO方式进行 无需等待上一次io返回结果再进行下一次io 且如果多次io操作的页是顺序的 则可以合并成一次io进行处理
    mysql提供了用户级别的模拟AIO和操作系统的native AIO(与操作系统相关 MAC OS 不支持)
刷新临接页 脏页刷盘时 会检查临接的其他页是否需要刷入 若需要 则合并成一次io同时刷入
    当磁盘iops较高时 此特性可以关闭(磁盘写入效率较高且无法预测临接脏页刷入后会不会立刻又变成脏页)

innodb 表的物理结构
innodb 每个库中存在共享表空间和独立表空间 共享表空间存放undo log 事务信息 二次写缓冲 插入缓冲等信息 独立表空间存放每张表的数据 索引以及插入缓冲的bitmap信息
独立表空间的数据由段 区 页组成 一个表空间被分为多个逻辑的段 每个段中存在多个物理数据区 每个区由多个数据页组成 数据页中存放具体的数据 也是索引组织的最小单位
页包括 数据页 索引页 undo log页 事务数据页 系统页 行溢出的大数据页等
数据页 包括 具体的数据行 页的描述信息(在表空间的位置 页双向链表的上一页 下一页指针 页类型) 状态信息(记录数 首条记录位置 最后插入位置与方向 空闲空间链表指针 页的最大事务id 页的索引id和索引b+树中的层数)
           页记录的主键最小&最大值 页的空闲空间链表 页目录(按照页的主键排序的稀疏目录 聚簇索引记录的是每个数据页的最小主键 查询时先根据索引定位到数据页 再根据数据页中的主键目录 二分查找到对应的数据行)
           页的完整标识(判断页是否被损坏)

索引
hash(范围查找支持较差 存在自适应hash索引) 有序数组(插入支持较差) 二叉树(树的层级较高 有更多的io操作) b+树(层级适中 搜索与插入性能较高)
innodb b+树页的分裂
    若对页的插入操作均为随机的 则页满时分裂两个相同大小的页
    若对页的插入在一定操作历史范围内是顺序的 则 若插入的记录后存在3条记录 则从后三条记录起进行分裂 否则从插入的记录开始分裂
innodb b+树页的合并
    相邻两个页容量都低于50%时合并成一个页
使用自增数字为主键 尽量的顺序插入 可以减少页的分裂与页的碎片 且可以减少非聚簇索引叶子节点的大小(为了减少维护成本 非聚簇索引的叶子节点记录了记录的具体主键值 而不是对应数据页的指针)
b+树的层数与一个节点(数据页)的大小相关 可以通过控制索引字段的大小或page的大小间接控制层数
cardinality(innodb 选择是否使用索引的关键值 预估了索引字段值的重复程度 当修改数据的操作大于一定值/修改数据的数量超过全表记录数的一定值后/通过sql手动触发 会刷新cardinality)
    统计策略是 随机寻找8个索引的叶子节点 统计索引值的不同值的个数 cardinality = 不同值的个数 / 8 * 叶子节点的数量 
若cardinality值过小 说明此索引重复数据过大 使用索引并无太大意义
联合索引(每个节点存在2个或以上字段 且根据索引顺序排序)
覆盖索引(指定要搜索的列而尽量避免回表)
前缀索引(联合索引遵循最左匹配原则)
Multi-Range Read(MRR) 对使用辅助索引来讲 现将命中的记录放入缓存中 然后根据记录的rowid(主键id)排序 然后再回表查找具体记录(减少磁盘随机读) 
                      同时会进行一定的查询拆分优化(若联合索引(a， b) where a > 0 and a < 1000 and b = 1000 拆分成where a = 1 and b = 1000/where a = 2 and b = 1000...)提前过滤数据
索引下推(匹配最左索引字段后检查索引包含其他字段 尽量过滤数据而避免回表以及返回给mysql 执行器过多数据)

锁
mysql锁分为 共享锁(S锁) 排它锁(X锁)两种 对于数据来讲 锁只被作用在数据行上 这些锁信息被记录在数据行对于的页上 在一页中 给一行记录加锁或给多行记录加同样的锁 对于性能和空间的损耗几乎可以忽略不计
在对某一数据行加锁时 mysql会对表加入意向锁(意向共享锁&意向排它锁 IS&IX)用来标识此表存在的锁类型 当有表锁产生时(修改表结构 重建索引可能产生表锁)不必依次检查数据行上的锁 只需检查表的意向锁即可
对于行级别锁 分为行锁 间隙锁(锁定索引上此节点后一个节点 对于非唯一索引 当获取锁时 会检查当前节点和前后节点的锁) 行锁+间隙锁 三种 当对非唯一索引的记录加锁时 会加入行锁+间隙锁 来保证不出现幻读(对于同一个事物中的两条相同的sql 执行结果不同)
    对于非聚簇索引上的间隙锁 会同时在非聚簇索引和聚簇索引上加入间隙锁和行锁(如果不在主键索引上加锁 若table_a中有a b c三列 a为主键 b存在非唯一索引 存在记录(1, 1, 1) 两个事物执行select a , b , c from table_a where b = 1 for update / update table_a set c = 5 where a = 1 会发生幻读)
    简单总结 对于一条确定的记录查询(表全局唯一) 仅会产生行锁 对于一条非唯一记录查询 会产生行锁+间隙锁
对于普通的select 并不会检查或产生锁(一致性非锁定读) 而是通过事物链表快照+数据版本链表(由undo log产生)来确定查询记录的值(mvcc)
    每条数据行会维护历史版本数据链表(数据值+事务id) 当新事务开启或存在加锁操作的sql被执行时 都会生产一个当前活跃的事务链表快照(已提交事务+未提交事务 维护在此事务描述中)
    事务隔离级别 在读未提交下 普通select会选取当前数据版本返回(若未提交的事务回滚 产生脏读)
               在读已提交下 会根据活跃事务链表快照 选取最近一个已提交事务的数据版本返回
               在可重复读下 会根据活跃事务链表快照 选取最近一个已提交事务且事务id小于当前事务的数据版本返回(保证两次相同条件下的非加锁查询的数据一致性)
自增主键 在mysql中 自增主键并非完全严格顺序递增的(事务回滚 一次性申请一批自增id 分表场景)
    mysql维护一个自增锁来保证并发请求时自增id的递增性质 (使用表全局的锁 不随事务提交释放 而是自增量访问完成后立刻释放或使用轻量级互斥量(mutex))

事务
ACID特性
    atomicity 原子性(同一事物中所有操作对应用来讲为原子操作 任一操作失败 全部操作回滚)
    consistency 一致性(事务使数据库从一个一致性状态转变成下一个一致性状态 不存在中间状态)
    isolation 隔离性(两个事务之间互不影响 一个事物不会读到其他事物未提交或提交的数据)
    durability 持久性(事务提交后数据即永久保留 不受应用或应用载体状态的影响)
标准的事务隔离级别(读未提交 读已提交 可重复度 串行化)
分布式事务(XA两阶段提交)
    mysql内部的XA事务(binlog与redo log 先记录redo log 标识为prepare 再记录binlog 成功后标识redo log为commit)
    服务之间的XA事务(事务管理器发起任务 服务依次报告是否可执行 通过后事务管理器发起执行并报告执行结果 管理器收到报告 全部成功则通知服务commit 有一个失败则通知服务rollback 服务收到后回复管理器收到消息 若管理器未收到回执则重复发送)
group commit(组提交) 此优化针对redo log&binlog 写入缓冲后的刷盘操作 由于刷盘的io开销相对较大 一次刷盘后将下一次需要刷盘的多次操作合并为一个  提高io效率(等待刷盘的binlog维护在一个链表中 进行group commit后按顺序通知redo log commit 保证binlog和redo log刷盘时的顺序一致性)
binlog设置为statement时在主从架构中的问题
    statement的binlog记录执行的具体sql 在读已提交的场景下 若事务a执行删除操作未提交(delete where id < 5) 事务b执行插入操作并提交(insert id = 3) 之后事务a提交 此时在同步给slave的binlog为先insert后delete(按照事务的提交顺序) 和master上真正的sql执行顺序相反 导致主从不一致
    避免此种现象有两种方案 使用可重复读的事务隔离级别(delete时加入间隙锁 只有等a事务提交后b事务才可执行)
                        使用row模式的binlog 此时binlog记录的是每一行的变化(事务a记录数据行无变化 事务b记录插入的数据行变化 事务的提交顺序并不会影响主从一致性)